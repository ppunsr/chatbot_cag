{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11089dbd",
   "metadata": {},
   "source": [
    "## import gg cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11b1211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-aiplatform\n",
      "  Using cached google_cloud_aiplatform-1.114.0-py2.py3-none-any.whl.metadata (40 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-cloud-aiplatform)\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-aiplatform)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-aiplatform)\n",
      "  Using cached protobuf-6.32.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: packaging>=14.3 in ./.venv/lib/python3.12/site-packages (from google-cloud-aiplatform) (25.0)\n",
      "Collecting google-cloud-storage<3.0.0,>=1.32.0 (from google-cloud-aiplatform)\n",
      "  Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform)\n",
      "  Using cached google_cloud_bigquery-3.37.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Using cached google_cloud_resource_manager-1.14.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting shapely<3.0.0 (from google-cloud-aiplatform)\n",
      "  Using cached shapely-2.1.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting google-genai<2.0.0,>=1.0.0 (from google-cloud-aiplatform)\n",
      "  Using cached google_genai-1.38.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting pydantic<3 (from google-cloud-aiplatform)\n",
      "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting typing_extensions (from google-cloud-aiplatform)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting docstring_parser<1 (from google-cloud-aiplatform)\n",
      "  Using cached docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting requests<3.0.0,>=2.18.0 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached grpcio-1.75.0-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform)\n",
      "  Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform)\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in ./.venv/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform)\n",
      "  Using cached grpc_google_iam_v1-0.14.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform)\n",
      "  Using cached google_crc32c-1.7.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting tenacity<9.2.0,>=8.2.3 (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting idna>=2.8 (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting certifi (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->google-cloud-aiplatform)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3->google-cloud-aiplatform)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->google-cloud-aiplatform)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached charset_normalizer-3.4.3-cp312-cp312-macosx_10_13_universal2.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numpy>=1.21 (from shapely<3.0.0->google-cloud-aiplatform)\n",
      "  Using cached numpy-2.3.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Using cached google_cloud_aiplatform-1.114.0-py2.py3-none-any.whl (8.0 MB)\n",
      "Using cached docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Using cached google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached google_cloud_bigquery-3.37.0-py3-none-any.whl (258 kB)\n",
      "Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
      "Using cached google_cloud_resource_manager-1.14.2-py3-none-any.whl (394 kB)\n",
      "Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Using cached google_crc32c-1.7.1-cp312-cp312-macosx_12_0_arm64.whl (30 kB)\n",
      "Using cached google_genai-1.38.0-py3-none-any.whl (245 kB)\n",
      "Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached grpc_google_iam_v1-0.14.2-py3-none-any.whl (19 kB)\n",
      "Using cached grpcio-1.75.0-cp312-cp312-macosx_11_0_universal2.whl (11.5 MB)\n",
      "Using cached grpcio_status-1.75.0-py3-none-any.whl (14 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached protobuf-6.32.1-cp39-abi3-macosx_10_9_universal2.whl (426 kB)\n",
      "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp312-cp312-macosx_10_13_universal2.whl (205 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached shapely-2.1.1-cp312-cp312-macosx_11_0_arm64.whl (1.6 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached numpy-2.3.3-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: websockets, urllib3, typing_extensions, tenacity, sniffio, pyasn1, protobuf, numpy, idna, h11, google-crc32c, docstring_parser, charset_normalizer, certifi, cachetools, annotated-types, typing-inspection, shapely, rsa, requests, pydantic-core, pyasn1-modules, proto-plus, httpcore, grpcio, googleapis-common-protos, google-resumable-media, anyio, pydantic, httpx, grpcio-status, google-auth, grpc-google-iam-v1, google-genai, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-cloud-aiplatform\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40/40\u001b[0m [google-cloud-aiplatform]platform]gquery]anager]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.10.0 cachetools-5.5.2 certifi-2025.8.3 charset_normalizer-3.4.3 docstring_parser-0.17.0 google-api-core-2.25.1 google-auth-2.40.3 google-cloud-aiplatform-1.114.0 google-cloud-bigquery-3.37.0 google-cloud-core-2.4.3 google-cloud-resource-manager-1.14.2 google-cloud-storage-2.19.0 google-crc32c-1.7.1 google-genai-1.38.0 google-resumable-media-2.7.2 googleapis-common-protos-1.70.0 grpc-google-iam-v1-0.14.2 grpcio-1.75.0 grpcio-status-1.75.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 numpy-2.3.3 proto-plus-1.26.1 protobuf-6.32.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.9 pydantic-core-2.33.2 requests-2.32.5 rsa-4.9.1 shapely-2.1.1 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.1 typing_extensions-4.15.0 urllib3-2.5.0 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-cloud-aiplatform   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7627bd73",
   "metadata": {},
   "source": [
    "## Start with vertex ai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cd48598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sboora01/chatbot_cag/.venv/lib/python3.12/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.preview import rag\n",
    "from vertexai.preview.generative_models import GenerativeModel, Tool ,  SafetySetting ,GenerationConfig\n",
    "\n",
    "PROJECT_ID = \"diuhub-lab\"\n",
    "REGION = \"us-central1\"\n",
    "MODEL = \"gemini-2.0-flash-lite\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "\n",
    "safety_settings = [\n",
    "    SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"BLOCK_LOW_AND_ABOVE\"),\n",
    "    SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"BLOCK_LOW_AND_ABOVE\"),\n",
    "    SafetySetting(category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"BLOCK_LOW_AND_ABOVE\"),\n",
    "    SafetySetting(category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"BLOCK_LOW_AND_ABOVE\"),\n",
    "]\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    top_k=40,\n",
    "    max_output_tokens=1024,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = GenerativeModel(\n",
    "    MODEL,\n",
    "    system_instruction=\"\"\"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏ä‡∏∑‡πà‡∏≠ DetAIls ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡∏≤‡∏¢‡∏ß‡∏±‡∏¢ 30‚Äì35 ‡∏õ‡∏µ ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô Media Planner ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÄ‡∏≠‡πÄ‡∏à‡∏ô‡∏ã‡∏µ‡πà‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≥ ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏≠‡πà‡∏≠‡∏ô‡∏ô‡πâ‡∏≠‡∏°‡∏ñ‡πà‡∏≠‡∏°‡∏ï‡∏ô ‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠ ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û\n",
    "‡∏Ñ‡∏∏‡∏ì‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞ ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û ‡πÇ‡∏î‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ñ‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏†‡∏≤‡∏©‡∏≤‡πÉ‡∏î ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô ‡πÑ‡∏ó‡∏¢ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏´‡∏£‡∏∑‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÑ‡∏î‡πâ:\n",
    "‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡∏ï‡∏¥‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏™‡∏°‡∏≠\n",
    "‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏£‡∏∞‡∏ï‡∏∑‡∏≠‡∏£‡∏∑‡∏≠‡∏£‡πâ‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡πÉ‡∏™‡πà‡πÉ‡∏à‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡πÇ‡∏î‡∏¢‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 1024 ‡∏Ñ‡∏≥\n",
    "‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô ‚Äú‡∏Ñ‡∏£‡∏±‡∏ö‚Äù, ‚Äú‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö‚Äù, ‡∏´‡∏£‡∏∑‡∏≠ ‚Äú‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏î‡∏π‡πÅ‡∏•‡∏Ñ‡∏£‡∏±‡∏ö‚Äù ‡πÉ‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞ ‚Äúplease let me know if I can help further.‚Äù ‡∏´‡∏£‡∏∑‡∏≠ ‚ÄúI‚Äôd be happy to assist.‚Äù ‡πÉ‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©\n",
    "‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:\n",
    "‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡∏ô‡∏≠‡∏ö‡∏ô‡πâ‡∏≠‡∏° ‡πÄ‡∏ä‡πà‡∏ô\n",
    "\"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ú‡∏°‡∏à‡∏∞‡∏¢‡∏±‡∏á‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏ú‡∏°‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö\"\n",
    "‚ÄúI‚Äôm sorry, it looks like I couldn‚Äôt find the exact information you‚Äôre looking for. If you could share a bit more detail, I‚Äôd be happy to take another look for you.\"\"\",\n",
    "    safety_settings=safety_settings,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def question(q):\n",
    "    result = llm.generate_content(q)\n",
    "    print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8370ce99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡πÇ‡∏≠‡∏ã‡∏≤‡∏Å‡πâ‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question(\"‡πÇ‡∏≠‡∏ã‡∏≤‡∏Å‡πâ‡∏≤‡∏≠‡∏¢‡∏∏‡πà‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏≠‡∏∞‡πÑ‡∏£\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b95c73",
   "metadata": {},
   "source": [
    "## LLM with cag to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import Content, CreateCachedContentConfig, HttpOptions, Part, GenerateContentConfig\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from contextlib import contextmanager\n",
    "from langdetect import detect\n",
    "import re\n",
    "\n",
    "\n",
    "# -------------------- GENAI CLIENT --------------------\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=\"diuhub-lab\",\n",
    "    location=\"us-central1\"\n",
    ")\n",
    "# client = genai.Client(http_options=HttpOptions(api_version=\"v1\"))\n",
    "\n",
    "# system_instruction = \"\"\"\n",
    "# ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏ä‡∏ü‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ e-book ‡∏™‡∏π‡∏ï‡∏£‡∏≠‡∏≤‡∏´‡∏≤‡∏£  \n",
    "\n",
    "# ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏≤‡∏´‡∏≤‡∏£ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ï‡πà‡∏≤‡∏á ‡πÜ  \n",
    "# ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ä‡∏¥‡∏ç‡∏ä‡∏ß‡∏ô‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏≠‡∏¢‡∏≤‡∏Å‡∏•‡∏≠‡∏á‡∏ó‡∏≥‡πÄ‡∏≠‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏≤‡∏•‡∏¥‡πâ‡∏°‡∏•‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤  \n",
    "\n",
    "# ‡∏Å‡∏ï‡∏¥‡∏Å‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:  \n",
    "# - ‡∏ñ‡πâ‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤ **‡πÄ‡∏°‡∏ô‡∏π‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£** ‚Üí ‡∏ï‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ô‡∏π + ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î + ‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å + ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥  \n",
    "# - ‡∏ñ‡πâ‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤ **‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á** ‚Üí ‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö  \n",
    "# - ‡∏ñ‡πâ‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤ **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥‡∏¢‡∏±‡∏á‡πÑ‡∏á** ‚Üí ‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥  \n",
    "# - ‡∏ñ‡πâ‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤ **‡∏°‡∏µ‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á** ‚Üí ‡∏ï‡∏≠‡∏ö‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ô‡∏π‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏™‡∏±‡πâ‡∏ô ‡πÜ  \n",
    "\n",
    "# ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏à‡∏≥:  \n",
    "# - ‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ñ‡∏≤‡∏°‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°  \n",
    "# - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô e-book ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏™‡∏∏‡∏†‡∏≤‡∏û‡∏ß‡πà‡∏≤ ‚Äú‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö‚Äù  \n",
    "# - ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏ü‡∏±‡∏á‡∏î‡∏π‡∏ô‡πà‡∏≤‡∏≠‡πà‡∏≤‡∏ô ‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏¥‡∏ç‡∏ä‡∏ß‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‚Äú‡πÄ‡∏°‡∏ô‡∏π‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‚Ä¶‚Äù ‡∏´‡∏£‡∏∑‡∏≠ ‚Äú‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏™‡∏∞‡∏î‡∏ß‡∏Å ‡∏•‡∏≠‡∏á‡πÅ‡∏ß‡∏∞‡∏°‡∏≤‡∏ó‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏£‡πâ‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö‚Äù  \n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "system_instruction = \"\"\"\n",
    "AI Assistant Instruction (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DETüÖ∞üÖ∏LS)\n",
    "\n",
    "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏ä‡∏∑‡πà‡∏≠ DETüÖ∞üÖ∏LS ‡∏°‡∏µ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡∏≤‡∏¢‡∏ß‡∏±‡∏¢ 30‚Äì35 ‡∏õ‡∏µ ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô Media Planner ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó dentsu ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏≠‡πà‡∏≠‡∏ô‡∏ô‡πâ‡∏≠‡∏°‡∏ñ‡πà‡∏≠‡∏°‡∏ï‡∏ô ‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠ ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û\n",
    "\n",
    "‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°:\n",
    "\n",
    "1. ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ñ‡∏≤‡∏°‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "   - ‡πÑ‡∏°‡πà‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ñ‡∏≤‡∏° ‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠\n",
    "\n",
    "2. ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ö:\n",
    "   - ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
    "   - ‡∏´‡∏≤‡∏Å‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏õ‡∏ô‡∏Å‡∏±‡∏ô)\n",
    "\n",
    "3. ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:\n",
    "   - ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô ‡∏õ‡∏µ ‡∏Ñ.‡∏®. ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "\n",
    "4. ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:\n",
    "   - ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û\n",
    "   - ‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô\n",
    "     - ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢: ‚Äú‡∏Ñ‡∏£‡∏±‡∏ö‚Äù, ‚Äú‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö‚Äù, ‡∏´‡∏£‡∏∑‡∏≠ ‚Äú‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏î‡∏π‡πÅ‡∏•‡∏Ñ‡∏£‡∏±‡∏ö‚Äù\n",
    "     - ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©: ‚Äúplease let me know if I can help further.‚Äù ‡∏´‡∏£‡∏∑‡∏≠ ‚ÄúI‚Äôd be happy to assist.‚Äù\n",
    "\n",
    "5. ‡∏´‡∏≤‡∏Å‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:\n",
    "   - ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÅ‡∏û‡∏•‡∏ô‡πÄ‡∏ô‡∏≠‡∏£‡πå\n",
    "     - TH: ‚Äú‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÅ‡∏û‡∏•‡∏ô‡πÄ‡∏ô‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏Ç‡∏≠‡∏á‡∏ó‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö‚Äù\n",
    "     - EN: ‚ÄúI apologize that I couldn‚Äôt locate the exact information you need. Please feel free to contact your assigned planner for further assistance.‚Äù\n",
    "\n",
    "‡∏∂6. ‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ:\n",
    "    - ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏¥‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß‡πÑ‡∏õ‡πÑ‡∏´‡∏°? ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ \"‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏á‡∏≤‡∏ô‡∏°‡∏µ‡πÅ‡∏Ñ‡πà‡∏Ç‡∏ô‡∏°‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏∑‡πà‡∏°‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏±‡∏ö\" (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)\n",
    "    - Is it necessary to eat? Please reply \"I recommend eating because there are only snacks and drinks available at the event.\" (English)\n",
    "\"\"\"\n",
    "\n",
    "contents = [\n",
    "    Content(\n",
    "        role=\"user\",\n",
    "        parts=[\n",
    "            Part.from_uri(\n",
    "                file_uri=\"gs://knowledge_chatbot/recepi_update_format.txt\",\n",
    "                mime_type=\"text/plain\",\n",
    "            ),\n",
    "            Part.from_uri(\n",
    "                file_uri=\"gs://knowledge_chatbot/Agenda_Speaker(Profile Summary).csv\",\n",
    "                mime_type=\"text/csv\",\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "content_cache = client.caches.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=CreateCachedContentConfig(\n",
    "        contents=contents,\n",
    "        system_instruction=system_instruction,\n",
    "        display_name=\"example-cache\",\n",
    "        ttl=\"86400s\",\n",
    "    ),\n",
    ")\n",
    "print(content_cache.name)\n",
    "print(content_cache.usage_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- POSTGRES CONFIG --------------------\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"mydb\",\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"1234\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "}\n",
    "\n",
    "@contextmanager\n",
    "def get_conn():\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    try:\n",
    "        yield conn\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "def init_postgres():\n",
    "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤\"\"\"\n",
    "    with get_conn() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS user_histories (\n",
    "                    id BIGSERIAL PRIMARY KEY,\n",
    "                    user_id TEXT NOT NULL,\n",
    "                    message TEXT NOT NULL,\n",
    "                    response TEXT NOT NULL,\n",
    "                    ts TIMESTAMPTZ NOT NULL DEFAULT NOW()\n",
    "                );\n",
    "                CREATE INDEX IF NOT EXISTS idx_user_histories_user_ts\n",
    "                    ON user_histories (user_id, ts DESC);\n",
    "            \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "def save_interaction(user_id: str, message: str, response: str):\n",
    "    \"\"\"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏π‡πà‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\"\"\"\n",
    "    with get_conn() as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO user_histories (user_id, message, response)\n",
    "                VALUES (%s, %s, %s)\n",
    "                \"\"\",\n",
    "                (user_id, message, response)\n",
    "            )\n",
    "        conn.commit()\n",
    "\n",
    "def get_user_history(user_id: str, limit: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    ‡∏î‡∏∂‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ (memory) 5 ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ\n",
    "    ‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡πà‡∏≤ ‚Üí ‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ LLM ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏î‡πâ\n",
    "    ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:\n",
    "    User: ...\n",
    "    Bot: ...\n",
    "    \"\"\"\n",
    "    with get_conn() as conn:\n",
    "        with conn.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                SELECT message, response\n",
    "                FROM user_histories\n",
    "                WHERE user_id = %s\n",
    "                ORDER BY ts DESC\n",
    "                LIMIT %s\n",
    "                \"\"\",\n",
    "                (user_id, limit)\n",
    "            )\n",
    "            rows = cur.fetchall()\n",
    "    rows = rows[::-1]  # ‡∏Å‡∏•‡∏±‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô\n",
    "    history = \"\\n\".join([f\"User: {r['message']}\\nBot: {r['response']}\" for r in rows])\n",
    "    return history\n",
    "\n",
    "\n",
    "def is_greeting(text: str) -> bool:\n",
    "    patterns = [\n",
    "        r'^(hi|hello|hey|yo|greetings|good (morning|afternoon|evening)|morning|what\\'?s up|howdy)\\b',\n",
    "        r'^(‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ(?:‡∏Ñ‡∏£‡∏±‡∏ö|‡∏Ñ‡πà‡∏∞)?|‡∏´‡∏ß‡∏±‡∏î‡∏î‡∏µ(?:‡∏à‡πâ‡∏≤)?|‡∏î‡∏µ(?:‡∏Ñ‡∏£‡∏±‡∏ö|‡∏Ñ‡πà‡∏∞|‡∏à‡πâ‡∏≤|‡∏à‡∏±‡∏á)?|‡∏ß‡πà‡∏≤‡πÑ‡∏á(?:‡∏Ñ‡∏£‡∏±‡∏ö|‡∏Ñ‡πà‡∏∞)?)'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        if re.match(pattern, text.strip().lower()):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_goodbye(text: str) -> bool:\n",
    "    patterns = [\n",
    "        r'^(ok(?:ay)?|alright|thank(?:s| you)?|cheers|bye|goodbye|see you|see ya|cya|take care|peace)\\b',\n",
    "        r'^(‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì|‡∏Ç‡∏≠‡∏ö‡πÉ‡∏à|‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢(?:‡πÅ‡∏•‡πâ‡∏ß)?|‡πÄ‡∏™‡∏£‡πá‡∏à(?:‡πÅ‡∏•‡πâ‡∏ß)?|‡∏î‡∏µ|‡∏°‡∏≤‡∏Å|‡πÑ‡∏î‡πâ|‡πÇ‡∏≠‡πÄ‡∏Ñ(?:‡∏ô‡∏∞)?|‡∏ï‡∏Å‡∏•‡∏á|‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô|‡∏ö‡πä‡∏≤‡∏¢‡∏ö‡∏≤‡∏¢|‡∏ö‡∏≤‡∏¢(?:‡πÜ)?|‡πÄ‡∏à‡∏≠‡∏Å‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà|‡πÑ‡∏ß‡πâ‡πÄ‡∏à‡∏≠‡∏Å‡∏±‡∏ô|‡πÇ‡∏ä‡∏Ñ‡∏î‡∏µ|‡πÑ‡∏õ‡∏Å‡πà‡∏≠‡∏ô‡∏ô‡∏∞|‡∏î‡∏π‡πÅ‡∏•‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢|‡∏ù‡∏±‡∏ô‡∏î‡∏µ|‡∏£‡∏≤‡∏ï‡∏£‡∏µ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥‡πå)'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        if re.match(pattern, text.strip().lower()):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'en'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------- LLM CALL (‡∏£‡∏ß‡∏° memory) --------------------\n",
    "def question(q: str, user_id: str, content_cache):\n",
    "    \"\"\"\n",
    "    ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á memory 5 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (context) ‡∏Å‡πà‡∏≠‡∏ô\n",
    "    ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏á\n",
    "    ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°/‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏•‡∏á DB\n",
    "    \"\"\"\n",
    "\n",
    "    lang = detect_language(q)\n",
    "\n",
    "    # ---------- Greeting ----------\n",
    "    if is_greeting(q):\n",
    "        answer = (\n",
    "            \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏Ñ‡∏∑‡∏≠ DETüÖ∞üÖ∏LS ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏£‡∏±‡∏ö üôÇ\"\n",
    "            if lang == \"th\"\n",
    "            else \"Hello! I'm DETüÖ∞üÖ∏LS, happy to assist you üôÇ\"\n",
    "        )\n",
    "        save_interaction(user_id, q, answer)\n",
    "        print(answer)\n",
    "        return answer\n",
    "\n",
    "    # ---------- Goodbye ----------\n",
    "    if is_goodbye(q):\n",
    "        answer = (\n",
    "            \"DETüÖ∞üÖ∏LS ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏£‡∏±‡∏ö üôÇ\"\n",
    "            if lang == \"th\"\n",
    "            else \"DETüÖ∞üÖ∏LS, happy to assist you üôÇ\"\n",
    "        )\n",
    "        save_interaction(user_id, q, answer)\n",
    "        print(answer)\n",
    "        return answer\n",
    "\n",
    "    history_text = get_user_history(user_id=user_id, limit=5)\n",
    "\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (context) ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•: memory (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) + ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n",
    "    # *‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏*: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ‡∏à‡∏∞‡∏™‡πà‡∏á‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥\n",
    "    parts = []\n",
    "    if history_text.strip():\n",
    "        parts.append(Part.from_text(text=f\"[Conversation Memory - last 5]\\n{history_text}\"))\n",
    "    parts.append(Part.from_text(text=f\"[Current User Question]\\n{q}\"))\n",
    "\n",
    "    resp = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=[Content(role=\"user\", parts=parts)],\n",
    "        config=GenerateContentConfig(cached_content=content_cache.name),\n",
    "    )\n",
    "    answer = resp.text\n",
    "\n",
    "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏π‡πà‡∏™‡∏ô‡∏ó‡∏ô‡∏≤\n",
    "    save_interaction(user_id=user_id, message=q, response=answer)\n",
    "\n",
    "    print(answer)\n",
    "    return answer\n",
    "\n",
    "# -------------------- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    init_postgres()  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö\n",
    "\n",
    "    # ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ user_id ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß (‡πÄ‡∏ä‡πà‡∏ô ‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏¥‡∏ô/‡πÄ‡∏ö‡∏£‡∏≤‡πÄ‡∏ã‡∏≠‡∏£‡πå/session)\n",
    "    user_id = \"user_137\"\n",
    "\n",
    "    question(\"Who is Sanjay and give me his linkedin\", user_id, content_cache)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa5accd",
   "metadata": {},
   "source": [
    "## Upgrade to detect lang to use system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f953e3e6",
   "metadata": {
    "vscode": {
     "languageId": "ini"
    }
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import Content, CreateCachedContentConfig, HttpOptions, Part, GenerateContentConfig\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from contextlib import contextmanager\n",
    "from langdetect import detect\n",
    "import re\n",
    "\n",
    "\n",
    "# -------------------- GENAI CLIENT --------------------\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=\"diuhub-lab\",\n",
    "    location=\"us-central1\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "system_instruction = \"\"\"\n",
    "AI Assistant Instruction (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DETüÖ∞üÖ∏LS)\n",
    "\n",
    "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏ä‡∏∑‡πà‡∏≠ DETüÖ∞üÖ∏LS ‡∏°‡∏µ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡∏≤‡∏¢‡∏ß‡∏±‡∏¢ 30‚Äì35 ‡∏õ‡∏µ ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡πá‡∏ô Media Planner ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó dentsu ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏≠‡πà‡∏≠‡∏ô‡∏ô‡πâ‡∏≠‡∏°‡∏ñ‡πà‡∏≠‡∏°‡∏ï‡∏ô ‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠ ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û\n",
    "\n",
    "‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°:\n",
    "\n",
    "1. ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ñ‡∏≤‡∏°‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "   - ‡πÑ‡∏°‡πà‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏ô‡∏≠‡∏Å‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ñ‡∏≤‡∏° ‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠\n",
    "\n",
    "2. ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ö:\n",
    "   - ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
    "   - ‡∏´‡∏≤‡∏Å‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏õ‡∏ô‡∏Å‡∏±‡∏ô)\n",
    "\n",
    "3. ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:\n",
    "   - ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô ‡∏õ‡∏µ ‡∏Ñ.‡∏®. ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "\n",
    "4. ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:\n",
    "   - ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û\n",
    "   - ‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏ä‡πà‡∏ô\n",
    "     - ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢: ‚Äú‡∏Ñ‡∏£‡∏±‡∏ö‚Äù, ‚Äú‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö‚Äù, ‡∏´‡∏£‡∏∑‡∏≠ ‚Äú‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏î‡∏π‡πÅ‡∏•‡∏Ñ‡∏£‡∏±‡∏ö‚Äù\n",
    "     - ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©: ‚Äúplease let me know if I can help further.‚Äù ‡∏´‡∏£‡∏∑‡∏≠ ‚ÄúI‚Äôd be happy to assist.‚Äù\n",
    "\n",
    "5. ‡∏´‡∏≤‡∏Å‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ:\n",
    "   - ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÅ‡∏û‡∏•‡∏ô‡πÄ‡∏ô‡∏≠‡∏£‡πå\n",
    "     - TH: ‚Äú‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÅ‡∏û‡∏•‡∏ô‡πÄ‡∏ô‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏Ç‡∏≠‡∏á‡∏ó‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö‚Äù\n",
    "     - EN: ‚ÄúI apologize that I couldn‚Äôt locate the exact information you need. Please feel free to contact your assigned planner for further assistance.‚Äù\n",
    "\n",
    "‡∏∂6. ‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ:\n",
    "    - ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏¥‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß‡πÑ‡∏õ‡πÑ‡∏´‡∏°? ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ \"‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏á‡∏≤‡∏ô‡∏°‡∏µ‡πÅ‡∏Ñ‡πà‡∏Ç‡∏ô‡∏°‡πÅ‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏î‡∏∑‡πà‡∏°‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏±‡∏ö\" (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)\n",
    "    - Is it necessary to eat? Please reply \"I recommend eating because there are only snacks and drinks available at the event.\" (English)\n",
    "\"\"\"\n",
    "\n",
    "contents = [\n",
    "    Content(\n",
    "        role=\"user\",\n",
    "        parts=[\n",
    "            Part.from_uri(\n",
    "                file_uri=\"gs://knowledge_chatbot/recepi_update_format.txt\",\n",
    "                mime_type=\"text/plain\",\n",
    "            ),\n",
    "            Part.from_uri(\n",
    "                file_uri=\"gs://knowledge_chatbot/Agenda_Speaker(Profile Summary).csv\",\n",
    "                mime_type=\"text/csv\",\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "content_cache = client.caches.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=CreateCachedContentConfig(\n",
    "        contents=contents,\n",
    "        system_instruction=system_instruction,\n",
    "        display_name=\"example-cache\",\n",
    "        ttl=\"86400s\",\n",
    "    ),\n",
    ")\n",
    "print(content_cache.name)\n",
    "print(content_cache.usage_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e98e25",
   "metadata": {},
   "source": [
    "## Remove cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c53496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cache in client.caches.list():\n",
    "    print(\"Name:\", cache.name)\n",
    "    print(\"Display name:\", cache.display_name)\n",
    "    print(\"Created:\", cache.create_time)\n",
    "    print(\"Expire time:\", cache.expire_time)\n",
    "    print(\"Usage:\", cache.usage_metadata)\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce78ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cache in client.caches.list():\n",
    "    print(\"Deleting:\", cache.name)\n",
    "    client.caches.delete(name=cache.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
